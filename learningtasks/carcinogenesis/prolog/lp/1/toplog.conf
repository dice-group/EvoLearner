[main]
; configuration options taken from the GILPS manual
; http://www.doc.ic.ac.uk/~jcs06/GILPS/Manual.pdf

; If true and there are output variables in the modeh declaration, stops the
; construction of the most-specific clause in the earliest layer where all
; the output variables have already occurred. If false or there are no output
; variables in the modeh declaration, constructs the bottom clause normally
; up to depth ’i’. This setting is only applicable to ILP engines which use
; most-specific clauses (i.e. ProGolem and FuncLog).
; (Default=false)
;bottom_early_stop=false

; Defines the clause evaluation engine to use when computing the coverage of
; a clause. This setting is applicable to all ILP systems in GILPS but is
; particularly important to ProGolem, as ProGolem will generate much larger
; clauses than a top-down ILP system.
; Possible choices for the clause evaluation engine are:
; - 'left_to_right': uses Prolog built-in left-to-right, depth-first search
;   heuristic for SLD-resolution. This is only advisable for very short or
;   determinate clauses.
; - 'smallest_predicate_domain': SLD-resolution with a selection heuristic
;   that selects at each moment the literal which has the fewest solutions.
;   This heuristic has an overhead compared with 'left-to-right' but, by
;   failing earlier in the search, handles non-determinate clauses better.
; - 'smallest variable domain': SLD-resolution with a selection heuristic
;   that selects at each moment the variable which has the fewest possible
;   values. This heuristic has an overhead compared with 'left-to-right'
;   and 'smallest predicate domain' but may pay off on non-determinate
;   clauses when the number of distinct variables is much smaller than the
;   number of literals in the clause.
; - 'advanced': identical to 'smallest variable domain' but decomposes a
;   clause recursively in independent sub-components. This engine has a
;   greater overhead than 'smallest variable domain' but may pay off on
;   decomposable non-determinate clauses.
; - 'theta subsumption': performs theta-subsumption, using Subsumer, between
;   hypothesis and example. Note that the background knowledge must be
;   pure-Prolog.
; (Default=smallest_predicate_domain)
;clause_evaluation=smallest_predicate_domain

; Defines the maximum number of literals (including the head) of a valid
; clause. ProGolem ignores this setting but TopLog and FuncLog adhere to it.
; (Default=4)
;clause_length=4

; Number of folds to perform cross-validation. A value of '1' instructs GILPS
; to use all examples for training. Remember that when an example is
; specified the user can pre-assign it to a specific fold
; (example(bind(p1T 10), −1, 3) --> bound to fold 3) . If there is no
; pre-assigned fold for an example, it will be assigned to a random fold.
; (Default=1)
;cross_validation_folds=1

; If 'true' applies the cut-transformation. The cut-transformation can only
; be applied if 'clause_evaluation=left_to_right'. The purpose of this
; transformation is to speed-up clause evaluation by transforming the clause
; before coverage computation. Although still applicable, the
; cut-transformation has mostly been superseded by the more sophisticated
; clause evaluation engines available through the 'clause evaluation' setting.
; (Default=false)
;cut_transformation=false

; Defines which ILP engine GILPS should use. The possibilities are currently:
; - 'toplog': TopLog is a top-down ILP system that uses a logic program
;   instead of mode declarations to define the hypothesis space.
; - 'progolem': ProGolem is a bottom-up ILP system using asymmetric relative
;   minimal generalizations as the specialization operator.
; - 'funclog': FuncLog is a specialized ILP learner for head output connected
;   predicates (i.e. functions).
; (Default=progolem)
;engine=toplog

; Defines which function to use when scoring a clause. Suppose this clause
; has NL literals and covers TP true positive examples, FP false positive
; examples, TN true negative examples and FN false negative examples. The
; total number of examples, E, is TP + FP + TN + FN. The most relevant
; scoring functions are:
; - 'accuracy': (TP + TN)/E
; - 'compression': TP − FP − NL
; - 'compression ratio': (TP − FP)/NL
; - 'coverage': TP − FP
; - 'novelty': TP/N − ((TP + FN) ∗ (TP + FP))/(E ∗ E)
; - 'precision': TP/(TP + FP)
; For a full list of available scoring functions see module
; 'hypotheses/score.pl', where you can also specify your own scoring function.
; (Default=compression)
;evalfn=compression

; Maximum depth for the proof of any clause. This setting is important to
; ensure the interpreter does not enter an infinite loop when evaluating
; badly behaved recursive hypotheses or background knowledge.
; (Default=20)
;depth=20

; The weight of each example as specified in the examples definition is
; multiplied by this factor. Remember that when defining the examples, it is
; possible to assign a custom weight for each example, therefore allowing
; some examples to be more important than others. Also notice that if
; 'example_inflation' is a negative number, the positive and negative
; examples swap places. See also positive_example_inflation and
; negative_example_inflation.
; (Default=1)
;example_inflation=1

; Defines the number of layers of new variables when constructing the
; most-specific clause for an example. This setting is ignored by TopLog
; as it does not need to construct most-specific clauses.
; (Default=3)
;i=3

; Maximum number of singleton variables (i.e. variables which just occur
; once) in a clause. This is a TopLog-specific setting.
; (Default=inf)
;maximum_singletons_in_clause=inf

; Maximum weight of negative examples that may be covered by a single clause.
; (Default=inf)
;maxneg=inf

; Maximum number of hypotheses in the final induced theory. The default value
; of 'inf' allows the addition of whatever number of clauses may be needed,
; as long as there is an incremental gain in adding these clauses to the
; current theory. The incremental gain is measured according to the evalfn
; setting and also considers the positive and negative examples the theory
; covers so far.
; (Default=inf)
;max_clauses_per_theory=inf

; This setting is only applicable when the clause evaluation engine is
; 'left_to_right'. It defines the maximum number of resolutions allowed
; before failing a coverage test. The maximum resolutions may be set to 'inf'
; to ensure proper coverage computation (i.e. infinite resolutions). Keep in
; mind, though, that if the clause under evaluation is long and
; non-determinate, it is likely the ILP system may take too long. In this
; case it is better to use another clause evaluation engine. See setting
; 'clause_evaluation' for the possible options and trade-offs.
; (Default=10000)
;max_resolutions=10000

; Maximum number of uncompressive examples (or negative score if other
; scoring function is being used) allowed before stopping the search and
; computing the current best theory. This setting is only applicable if
; 'theory_construction'=incremental.
; (Default=20)
;max_uncompressive_examples=20

; Minimum percentage accuracy a clause has to have on the training data to
; be considered a valid hypothesis.
; (Default=0)
;minacc=0

; Minimum percentage of the positive examples a clause has to cover to be
; considered a valid hypothesis.
; (Default=0)
;mincov=0

; Minimum number of singleton variables (i.e. variables which just occur
; once) in a clause. This is a TopLog-specific setting.
; (Default=0)
;minimum_singletons_in_clause=0

; Minimum weight of positive examples a clause has to cover to be considered
; a valid hypothesis.
; (Default=0)
;minpos=0

; Minimum percentage of corrected predicted positive examples a clause has to
; have to be considered a valid hypothesis.
; (Default=0)
;minprec=0

; Multiplies the weights of all negative examples by this factor. See also
; example inflation and positive example inflation.
; (Default=1)
;negative_example_inflation=1

; Maximum percentage of negative weights a clause may cover to still be
; considered a valid hypothesis.
; (Default=0.5)
;noise=0.5

; Maximum number of hypotheses that may be derived by a single positive
; example. This setting is TopLog specific.
; (Default=5000)
;nodes=5000

; Filename where the induced theory is written. If this file already exists,
; it will be overwritten.
; (Default=’theory.pl’)
;output_theory_file=theory.pl

; Multiplies the weights of all positive examples by this factor. See also
; example inflation and negative example inflation.
; (Default=1)
;positive_example_inflation=1

; This setting controls the pretty printing of clauses to the stdout. It
; specifies the number of literals to be displayed per line when showing a
; clause.
; (Default=4)
;print=4

; This is an integer specifying the random seed to be used by the ILP system.
; If the seed is the same across runs, the same numbers will be generated by
; the random number generators and results can be reproduced.
; (Default=7)
;random_seed=7

; This setting impacts the construction of the most-specific clause. For a
; given mode body declaration,modeb, if 'false' the atoms that will be added
; to the body of the most-specific clause are the first N matches of the
; modeb declaration against the background knowledge.
; If randomize_recall=true the N solutions are randomly selected from the set
; of all possible matches of the modeb declaration. This may be useful when
; the dataset has a degree of non-determinism higher than the star default
; recall and we do not want to introduce a bias to favour the first matches.
; In ILP systems which do not have this setting, e.g. Aleph and Progol, it
; is possible to emulate it by shuffling the background knowledge file.
; (Default=false)
;randomize_recall=false

; This is an experimental setting. When evaluating a literal in a clause,
; only the first recall bound on evaluation solutions for any literal are
; considered. The default value of 'inf' considers all the solutions, as is
; expected from Prolog semantics. A lower value would only consider the first
; solutions, which could wrongly conclude that a given clause does not cover
; an example when it does. Note that this setting is unrelated to
; star_default_recall.
; (Default=inf)
;recall_bound_on_evaluation=inf

; This setting is only applicable when theory_construction=incremental.
; If set to true, when asserting a new hypothesis to the theory, and in
; addition to remove the positive examples covered by this hypothesis clause,
; the negative examples the hypothesis covers are also removed.
; (Default=false)
;remove_negatives=false

; This is a real number between 0.0 and 1.0 specifying the approximate
; percentage of the user-supplied examples (both positive and negative) to be
; used by the ILP system. In order to speed-up the learning in datasets where
; there are too many examples, it may be useful to use a small fraction of
; the total examples. Ideally the ILP system should already do some form of
; sample coverage and that is planned for a future version of GILPS.
; (Default=1.0)
;sample=1.0

; If 'true' and the coverage of a prefix of the clause under evaluation is
; available, then the coverage of the clause under evaluation is computed on
; the subset of examples that its longest prefix clause covers. This setting
; speeds up coverage test considerably as examples not covered by a prefix of
; a clause are guaranteed not to be covered. This setting increases the
; memory footprint, however. Currently only TopLog is able to take advantage
; of smart coverage.
; (Default=true)
;smart_coverage=true

; The integer value specifying the recall to which a '*' ought to correspond
; in a modeb definition. The recall setting is an important setting that is
; used in the construction of the most-specific clause of an example. A
; higher recall implies a larger hypothesis space.
; (Default=10)
;star_default_recall=10

; In 'global' construction mode the theory is constructed after all
; hypotheses have been generated. The other possibility is 'incremental'
; construction. In 'incremental' mode there is a loop where the best
; hypothesis generated from an example is asserted to the final theory and
; all the positive examples this hypothesis covers are retracted. Incremental
; theory construction therefore requires fewer CPU resources than global
; coverage but is example order dependent and may lead to weaker theories.
; (Default=global)
;theory_construction=global

; An integer >= 0 controlling the verbosity of GILPS. The higher the verbose
; level, the more information is shown.
; (Default=1)
;verbose=1
